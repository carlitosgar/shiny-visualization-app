{
    "contents" : "# Authors:\n# Carlos Garc√≠a @ cm.garsua@gmail.com\n# Adam Alpire @ am.rivero13@gmail.com\n\n############################################################\n######### Titanic Classifier - Decision Trees ##############\n############################################################\n\n# Packages.\nlibrary(caret)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(vcd)\n\n# Importing data.\ntitanicData <- read.csv(\"./titanic.csv\")\n\n# Data cleaning\nfinalVars <- c(2,3,5,6,7,8,10,12) # Final features\ntitanicData <- titanicData[finalVars]\nnrow(titanicData) # 891 rows\ntitanicData <- na.omit(titanicData) # Final instances (NA).\nnrow(titanicData) # 714 rows\n\n# Data partition\ninTraining <- createDataPartition(titanicData$Survived, p = .75, list = FALSE)\ntraining <- titanicData[ inTraining,]\ntesting <- titanicData[ -inTraining,]\n\n# Trainig Decision Tree\nfitModel <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=training, method=\"class\")\nprp(fitModel)\nrsq.rpart(fitModel) # R-squared\ntestPred <- predict(fitModel, testing, type = \"class\")\nconfusionMatrix(testPred, testing$Survived)\nhelp(\"rpart\") # Check the parameters of Decision Trees\n\n# Tuning rpat(): \n# (1) Overfitted tree.\nfitModelTuned <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=training,\n                       method=\"class\", control=rpart.control( cp=0))\nprp(fitModelTuned)\nrsq.rpart(fitModelTuned)\ntestPredTuned <- predict(fitModelTuned, testing, type = \"class\")\nconfusionMatrix(testPredTuned, testing$Survived)\n\n# (2) Overfitted tree.\nfitModelTuned <- rpart(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, data=training,\n                       method=\"class\", control=rpart.control( minsplit=2,cp=0))\nprp(fitModelTuned)\nrsq.rpart(fitModelTuned)\ntestPredTuned <- predict(fitModelTuned, testing, type = \"class\")\nconfusionMatrix(testPredTuned, testing$Survived)\n\n# Parameters tuning\nfitControl <- trainControl(## 10-fold CV\n  method = \"repeatedcv\",\n  number = 10)\nset.seed(825)\nrpartFit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,\n                 data = training,\n                 method = \"rpart\",\n                 #tuneGrid = rpartParams,\n                 trControl = fitControl)\nrpartFit\nprp(rpartFit$finalModel)\nplot(rpartFit)\n\n# Selecting parameters\nrpartParams <- expand.grid(cp = c(0, 0.01, 0.02, 0.04, 0.07, 0.10),\n                           Cost = c(1, 2, 3, 5, 10))\nset.seed(825)\nrpartFit <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,\n                  data = training,\n                  method = \"rpartCost\",\n                  tuneGrid = rpartParams,\n                  trControl = fitControl)\nrpartFit\nprp(rpartFit$finalModel)\nplot(rpartFit)\n\n# Random forests (ntree=2000)\nset.seed(825)\nfitForest <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,\n                   data = training,\n                   method = \"rf\",\n                   trControl = fitControl,\n                   ntree = 2000,\n                   importance = TRUE\n)\nfitForest\nfitForest$finalModel\nplot(fitForest)\nvarImpPlot(fitForest$finalModel)\n\n# Random forests (ntree=2000) and mtry\nforestParams <- expand.grid(mtry= c(2,3,4,5,6,7,8,9))\nset.seed(825)\nfitForest2 <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked,\n                    data = training,\n                    method = \"rf\",\n                    trControl = fitControl,\n                    ntree = 2000,\n                    tuneGrid = forestParams,\n                    importance = TRUE)\nfitForest2\nfitForest2$finalModel\nplot(fitForest2)\nvarImpPlot(fitForest2$finalModel)\ngbmImp2 <- varImp(fitForest2)\nplot(gbmImp2)\n\n# Random forest VS Decision Tree\nPrediction <- predict(fitForest2, testing)\nPrediction2 <- predict(rpartFit, testing)\nconfusionMatrix(Prediction, testing$Survived)\nconfusionMatrix(Prediction2, testing$Survived)\n\n########################## Testing New Feature Cabin #########################\npreData <- read.csv(\"./titanic.csv\")\n# Data cleaning\nfinalVarsCabin <- c(2,3,5,6,7,8,10,11,12) # Final features\npreData <- preData[finalVarsCabin]\ncounts <- table(preData$Cabin)\ncounts\nbarplot(counts,main=\"Simple Bar Plot\",xlab=\"Cabin\", ylab=\"Frequency\")\nwrite.table(counts, file=\"./cabin.txt\", fileEncoding = \"UTF-8\")\ns <- sapply(strsplit(as.character(preData$Cabin) , split=\"[^A-z]\") , \"[\" , 1)\ns[is.na(s)] <- as.character('NA')\ns <- factor(s)\npreData$Cabin <- s\npreData <- na.omit(preData)\ncabinCounts <- table(preData$Cabin)\ncabinCounts\nbarplot(cabinCounts,main=\"Cabins\",xlab=\"Deck\", ylab=\"Frequency\",\n        col=topo.colors(12))\n\n# Data partition\ninTrainingCabin <- createDataPartition(preData$Survived, p = .75, list = FALSE)\ntrainingCabin <- preData[ inTrainingCabin,]\ntestingCabin <- preData[ -inTrainingCabin,]\n\nset.seed(825)\nrpartFitCabin <- train(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Cabin + Embarked,\n                  data = trainingCabin,\n                  method = \"rpartCost\",\n                  tuneGrid = rpartParams,\n                  trControl = fitControl)\nrpartFitCabin\nprp(rpartFitCabin$finalModel)\nplot(rpartFitCabin)\npredictionCabin <- predict(rpartFitCabin, testingCabin)\nconfusionMatrix(predictionCabin, testingCabin$Survived)\n##############################################################################",
    "created" : 1453679869013.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3301529454",
    "id" : "174738B0",
    "lastKnownWriteTime" : 1446675067,
    "path" : "~/Projects/R/TitanicClassifier/titanic.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 5,
    "source_on_save" : false,
    "type" : "r_source"
}